-- ============================================================================
-- Iceberg Tables: Load Modes
-- ============================================================================
-- COPY INTO for Iceberg tables supports two load modes that control how
-- data is processed during ingestion.

-- ----------------------------------------------------------------------------
-- Create Iceberg table (Snowflake-managed)
-- ----------------------------------------------------------------------------

-- First, create an external volume for storage
CREATE OR REPLACE EXTERNAL VOLUME iceberg_volume
    STORAGE_LOCATIONS = (
        (
            NAME = 's3_storage'
            STORAGE_PROVIDER = 'S3'
            STORAGE_BASE_URL = 's3://my-bucket/iceberg/'
            STORAGE_AWS_ROLE_ARN = 'arn:aws:iam::123456789012:role/iceberg-role'
        )
    );

-- Create Iceberg table
CREATE OR REPLACE ICEBERG TABLE raw.customers_iceberg (
    customer_id STRING,
    customer_name STRING,
    email STRING,
    created_at TIMESTAMP_NTZ,
    _loaded_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
)
    CATALOG = 'SNOWFLAKE'
    EXTERNAL_VOLUME = 'iceberg_volume'
    BASE_LOCATION = 'customers/';

-- ----------------------------------------------------------------------------
-- FULL_INGEST: Read and rewrite as Iceberg Parquet
-- ----------------------------------------------------------------------------
-- Snowflake reads the source files, processes them, and writes new 
-- Iceberg-compatible Parquet files. Works with any supported format.

-- Load from JSON
COPY INTO raw.customers_iceberg
FROM @external_stage/customers/json/
FILE_FORMAT = (TYPE = 'JSON')
LOAD_MODE = FULL_INGEST
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Load from CSV
COPY INTO raw.customers_iceberg
FROM @external_stage/customers/csv/
FILE_FORMAT = (TYPE = 'CSV' SKIP_HEADER = 1)
LOAD_MODE = FULL_INGEST;

-- Load from Avro
COPY INTO raw.customers_iceberg
FROM @external_stage/customers/avro/
FILE_FORMAT = (TYPE = 'AVRO')
LOAD_MODE = FULL_INGEST
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- Load from non-Iceberg Parquet
COPY INTO raw.customers_iceberg
FROM @external_stage/customers/parquet/
FILE_FORMAT = (TYPE = 'PARQUET')
LOAD_MODE = FULL_INGEST
MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- ----------------------------------------------------------------------------
-- ADD_FILES_COPY: Direct copy of Iceberg-compatible Parquet
-- ----------------------------------------------------------------------------
-- Snowflake binary copies the Parquet files without scanning or rewriting.
-- Faster, but requires source files to already be Iceberg-compatible Parquet.

-- Requirements:
-- - Source must be Parquet
-- - Parquet schema must match table schema
-- - Files should follow Iceberg specifications

COPY INTO raw.customers_iceberg
FROM @parquet_stage/customers/
FILE_FORMAT = (TYPE = 'PARQUET' USE_VECTORIZED_SCANNER = TRUE)
LOAD_MODE = ADD_FILES_COPY
MATCH_BY_COLUMN_NAME = CASE_SENSITIVE;

-- ----------------------------------------------------------------------------
-- When to use each mode
-- ----------------------------------------------------------------------------

/*
FULL_INGEST:
- Source is JSON, CSV, Avro or non-Iceberg Parquet
- Need to transform data during load
- Schema mapping needed (column reordering, type casting)
- Files weren't generated for Iceberg

ADD_FILES_COPY:
- Source is already Iceberg-compatible Parquet
- Files were generated by Spark, Flink or another Iceberg writer
- Maximum load performance is needed
- No transformation required
*/

-- ----------------------------------------------------------------------------
-- Load with transformations (FULL_INGEST only)
-- ----------------------------------------------------------------------------

-- FULL_INGEST supports SELECT-based transformations
COPY INTO raw.customers_iceberg (
    customer_id,
    customer_name,
    email,
    created_at,
    _loaded_at
)
FROM (
    SELECT 
        $1:id::STRING as customer_id,
        $1:name::STRING as customer_name,
        LOWER($1:email::STRING) as email,
        $1:created::TIMESTAMP_NTZ as created_at,
        CURRENT_TIMESTAMP() as _loaded_at
    FROM @external_stage/customers/
)
FILE_FORMAT = (TYPE = 'JSON')
LOAD_MODE = FULL_INGEST;

-- ADD_FILES_COPY does NOT support transformations
-- Files must match target schema exactly

-- ----------------------------------------------------------------------------
-- Snowpipe with Iceberg tables
-- ----------------------------------------------------------------------------

-- Snowpipe works with Iceberg tables (uses FULL_INGEST internally)
CREATE OR REPLACE PIPE raw.customers_iceberg_pipe
    AUTO_INGEST = TRUE
    AS
    COPY INTO raw.customers_iceberg
    FROM @external_stage/customers/
    FILE_FORMAT = (TYPE = 'PARQUET')
    MATCH_BY_COLUMN_NAME = CASE_INSENSITIVE;

-- ----------------------------------------------------------------------------
-- Check Iceberg metadata
-- ----------------------------------------------------------------------------

-- View table properties
SHOW ICEBERG TABLES LIKE 'customers_iceberg';

-- Check snapshots (Iceberg version history)
SELECT * FROM TABLE(raw.customers_iceberg.SNAPSHOTS());

-- View manifest files
SELECT * FROM TABLE(raw.customers_iceberg.MANIFESTS());

-- View data files
SELECT * FROM TABLE(raw.customers_iceberg.FILES());

-- ----------------------------------------------------------------------------
-- Time travel with Iceberg
-- ----------------------------------------------------------------------------

-- Query at specific snapshot
SELECT * FROM raw.customers_iceberg AT(SNAPSHOT => '<snapshot_id>');

-- Query at timestamp
SELECT * FROM raw.customers_iceberg AT(TIMESTAMP => '2025-01-01 00:00:00'::TIMESTAMP);

-- ----------------------------------------------------------------------------
-- Maintenance operations
-- ----------------------------------------------------------------------------

-- Expire old snapshots (free up storage)
ALTER ICEBERG TABLE raw.customers_iceberg 
    EXECUTE EXPIRE SNAPSHOTS 
    OLDER_THAN '2025-01-01 00:00:00'::TIMESTAMP;

-- Compact data files (improve query performance)
ALTER ICEBERG TABLE raw.customers_iceberg 
    EXECUTE OPTIMIZE 
    WHERE created_at < '2025-01-01';
